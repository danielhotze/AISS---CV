{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlHJBGFlFvXq"
      },
      "source": [
        "## Step 1: Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "412fv-dVFrg8",
        "outputId": "7086040b-3dcf-4442-f1f7-e7de46778fe2"
      },
      "outputs": [],
      "source": [
        "## Lots of imports\n",
        "\n",
        "# Install Ultralytics YOLOv8\n",
        "!pip install ultralytics\n",
        "!pip install torchvision\n",
        "\n",
        "# Import necessary libraries\n",
        "import torch\n",
        "import os\n",
        "from ultralytics import YOLO\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKiCaiyXI96Y"
      },
      "source": [
        "Drive Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvf_0-mKF35K",
        "outputId": "4d86f03f-2ec6-4f5b-fbbe-3ac9d1997d89"
      },
      "outputs": [],
      "source": [
        "## If you did this correctly you should see here \"drive\" and \"sample_data\"\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmlWGwLCQ0gy",
        "outputId": "caa8fa00-a37b-46c5-d42b-ea9f3c63d2d3"
      },
      "outputs": [],
      "source": [
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgBExrvQFy_P"
      },
      "source": [
        "## Step 2: Data Import and Preperation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YSNm0RgJETC"
      },
      "outputs": [],
      "source": [
        "root = \"/content/drive/MyDrive/AISS - CV/2. Code/Model/Data_Reviewed\"\n",
        "images_folder = os.path.join(root, 'images')\n",
        "labels_folder = os.path.join(root, 'labels')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0b436gkt-PM"
      },
      "source": [
        "Build Transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSQ1javNd5p9"
      },
      "outputs": [],
      "source": [
        "train_val_transform = transforms.Compose([transforms.Resize(224),\n",
        "                           transforms.RandomRotation(6),\n",
        "                           transforms.RandomHorizontalFlip(0.4),\n",
        "                           transforms.RandomCrop(224, padding = 8),\n",
        "                           transforms.ToTensor()\n",
        "                       ])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "                           transforms.Resize(224),\n",
        "                           transforms.CenterCrop(224),\n",
        "                           transforms.ToTensor()\n",
        "                       ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJUuUjjWSiUP"
      },
      "source": [
        "Create datasets from Google Drive using Transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYNmXyoytM_f",
        "outputId": "6f8e4a67-a07f-45bf-ef1a-9f2526f5a9ab"
      },
      "outputs": [],
      "source": [
        "counter = 0\n",
        "\n",
        "# List all .txt files in the specified folder\n",
        "label_files = [f for f in os.listdir(labels_folder) if f.endswith('.txt')]\n",
        "\n",
        "# Count the number of label files\n",
        "for label in label_files:\n",
        "    counter += 1\n",
        "\n",
        "# Print the count\n",
        "print(counter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40sVX0vz6fdF",
        "outputId": "15172ca8-6bca-4ded-f08f-55eb19aada17"
      },
      "outputs": [],
      "source": [
        "# ChatGPT Version mit Cleanup\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define transformations\n",
        "train_val_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Custom function to load images and labels\n",
        "def load_dataset(images_folder, labels_folder, transform=None):\n",
        "    image_files = [f for f in os.listdir(images_folder) if f.endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'))]\n",
        "    dataset = []\n",
        "\n",
        "    for image_file in image_files:\n",
        "        # Load image\n",
        "        image_path = os.path.join(images_folder, image_file)\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "        if transform:\n",
        "            image = transform(image)\n",
        "\n",
        "        # Load corresponding label\n",
        "        label_file = os.path.splitext(image_file)[0] + \".txt\"\n",
        "        label_path = os.path.join(labels_folder, label_file)\n",
        "\n",
        "        if not os.path.exists(label_path):\n",
        "            continue\n",
        "\n",
        "        boxes = []\n",
        "        labels = []\n",
        "        with open(label_path, 'r') as f:\n",
        "            for line in f.readlines():\n",
        "                class_id, center_x, center_y, width, height = map(float, line.strip().split())\n",
        "                boxes.append([center_x, center_y, width, height])\n",
        "                labels.append(int(class_id))\n",
        "\n",
        "        boxes = torch.tensor(boxes, dtype=torch.float32)\n",
        "        labels = torch.tensor(labels, dtype=torch.int64)\n",
        "\n",
        "        dataset.append((image, {'boxes': boxes, 'labels': labels}))\n",
        "\n",
        "    return dataset\n",
        "\n",
        "# Function to clean up labels without corresponding images\n",
        "def clean_labels(images_folder, labels_folder):\n",
        "    image_files = {os.path.splitext(f)[0] for f in os.listdir(images_folder) if f.endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'))}\n",
        "    label_files = {os.path.splitext(f)[0] for f in os.listdir(labels_folder) if f.endswith('.txt')}\n",
        "\n",
        "    # Find label files without corresponding image files and remove them\n",
        "    labels_to_remove = label_files - image_files\n",
        "    for label in labels_to_remove:\n",
        "        label_path = os.path.join(labels_folder, label + \".txt\")\n",
        "        os.remove(label_path)\n",
        "\n",
        "    return len(label_files) - len(labels_to_remove)\n",
        "\n",
        "# Set the directories for images and labels\n",
        "root = '/content/drive/MyDrive/AISS - CV/2. Code/Model/Data_Reviewed'\n",
        "images_folder = os.path.join(root, 'images')\n",
        "labels_folder = os.path.join(root, 'labels')\n",
        "\n",
        "# Clean up the labels\n",
        "remaining_labels = clean_labels(images_folder, labels_folder)\n",
        "print(f\"The number of remaining labels is {remaining_labels}\")\n",
        "\n",
        "# Load the train/validation dataset\n",
        "train_val_dataset = load_dataset(images_folder, labels_folder, transform=train_val_transform)\n",
        "\n",
        "# Print the size of the train/validation dataset\n",
        "print(f\"The train/validation dataset contains {len(train_val_dataset)} labeled images\")\n",
        "\n",
        "# Example usage with DataLoader\n",
        "train_val_loader = DataLoader(train_val_dataset, batch_size=4, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
        "\n",
        "# Iterate through the DataLoader\n",
        "for images, targets in train_val_loader:\n",
        "    print(f\"Batch of images: {len(images)}\")\n",
        "    print(f\"Batch of targets: {len(targets)}\")\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0t3ABOVaGZ2R"
      },
      "outputs": [],
      "source": [
        "# Old Version - do not run (failed due to duplicates)\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define transformations\n",
        "train_val_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Custom function to load images and labels\n",
        "def load_dataset(images_folder, labels_folder, transform=None):\n",
        "    image_files = [f for f in os.listdir(images_folder) if f.endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'))]\n",
        "    dataset = []\n",
        "\n",
        "    for image_file in image_files:\n",
        "        # Load image\n",
        "        image_path = os.path.join(images_folder, image_file)\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "        if transform:\n",
        "            image = transform(image)\n",
        "\n",
        "        # Load corresponding label\n",
        "        label_file = os.path.splitext(image_file)[0] + \".txt\"\n",
        "        label_path = os.path.join(labels_folder, label_file)\n",
        "\n",
        "        boxes = []\n",
        "        labels = []\n",
        "        with open(label_path, 'r') as f:\n",
        "            for line in f.readlines():\n",
        "                class_id, center_x, center_y, width, height = map(float, line.strip().split())\n",
        "                boxes.append([center_x, center_y, width, height])\n",
        "                labels.append(int(class_id))\n",
        "\n",
        "        boxes = torch.tensor(boxes, dtype=torch.float32)\n",
        "        labels = torch.tensor(labels, dtype=torch.int64)\n",
        "\n",
        "        dataset.append((image, {'boxes': boxes, 'labels': labels}))\n",
        "\n",
        "    return dataset\n",
        "\n",
        "# Set the directories for images and labels\n",
        "root = '/content/drive/MyDrive/AISS - CV/2. Code/Model/Data_Reviewed'\n",
        "images_folder = os.path.join(root, 'images')\n",
        "labels_folder = os.path.join(root, 'labels')\n",
        "\n",
        "# Load the train/validation dataset\n",
        "train_val_dataset = load_dataset(images_folder, labels_folder, transform=train_val_transform)\n",
        "\n",
        "# Print the size of the train/validation dataset\n",
        "print(f\"The train/validation dataset contains {len(train_val_dataset)} labeled images\")\n",
        "\n",
        "# Example usage with DataLoader\n",
        "train_val_loader = DataLoader(train_val_dataset, batch_size=4, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
        "\n",
        "# Iterate through the DataLoader\n",
        "for images, targets in train_val_loader:\n",
        "    print(f\"Batch of images: {len(images)}\")\n",
        "    print(f\"Batch of targets: {len(targets)}\")\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPeP_v5DRLoC"
      },
      "source": [
        "Create Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IC1-d_IoRLQb"
      },
      "outputs": [],
      "source": [
        "#train_loader = DataLoader(train_val_dataset, batch_size=16, shuffle=True, num_workers=4)\n",
        "#val_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnfV4nO-F4RE"
      },
      "source": [
        "## Step 3: Pre-trained Model Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCcAdUxkDGtg",
        "outputId": "f5c9f2bc-8438-4bf0-93cd-abb501837cdd"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/AISS - CV/2. Code/Model\n",
        "!yolo task=detect mode=train model=yolov8s.pt data= data.yaml epochs=25 imgsz=224 plots=True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuGJezzK24NU"
      },
      "source": [
        "Inferece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWNOg04D22Nh",
        "outputId": "286c7a6b-e68b-4c85-ee4a-5a4f7d1ca28e"
      },
      "outputs": [],
      "source": [
        "!yolo task=detect mode=predict model='/content/drive/MyDrive/AISS - CV/2. Code/Model/runs/detect/train9/weights/best.pt' source='/content/drive/MyDrive/AISS - CV/3. Daten/Vasilis' imgsz=224 save=True show=True save_txt=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_hNIJvB-Vt9",
        "outputId": "56c5820f-433b-4ab8-85ce-e189c9bcca5c"
      },
      "outputs": [],
      "source": [
        "# Inference Vasilis\n",
        "!yolo task=detect mode=predict model='/content/drive/MyDrive/AISS - CV/2. Code/Model/runs/detect/train9/weights/best.pt' source='/content/drive/MyDrive/AISS - CV/3. Daten/Vasilis' imgsz=224 save=True show=True save_txt=True project='/content/drive/MyDrive/AISS - CV/Vasilis_results' name='detection_output'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjEJrRdh_9CD",
        "outputId": "b2307f90-f1d9-44c9-c828-c05b8cc6a178"
      },
      "outputs": [],
      "source": [
        "# Inference Isi\n",
        "!yolo task=detect mode=predict model='/content/drive/MyDrive/AISS - CV/2. Code/Model/runs/detect/train9/weights/best.pt' source='/content/drive/MyDrive/AISS - CV/3. Daten/Isabelle/AISS-CV_Isabelle' imgsz=224 save=True show=True save_txt=True project='/content/drive/MyDrive/AISS - CV/Isi_results' name='detection_output'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjeNiGWRAguX",
        "outputId": "70807724-d26f-49c9-bf34-21c8a6dab09a"
      },
      "outputs": [],
      "source": [
        "# Inference Luis\n",
        "!yolo task=detect mode=predict model='/content/drive/MyDrive/AISS - CV/2. Code/Model/runs/detect/train9/weights/best.pt' source='/content/drive/MyDrive/AISS - CV/3. Daten/Luis/AISS-CV_Luis' imgsz=224 save=True show=True save_txt=True project='/content/drive/MyDrive/AISS - CV/Luis_results' name='detection_output'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0heRy77DAvzG",
        "outputId": "4a1e1b8c-b632-4e10-afea-4218d5e74454"
      },
      "outputs": [],
      "source": [
        "# Inference Daniel\n",
        "!yolo task=detect mode=predict model='/content/drive/MyDrive/AISS - CV/2. Code/Model/runs/detect/train9/weights/best.pt' source='/content/drive/MyDrive/AISS - CV/3. Daten/Daniel' imgsz=224 save=True show=True save_txt=True project='/content/drive/MyDrive/AISS - CV/Daniel_results' name='detection_output'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiIcjL9G233i",
        "outputId": "fa563c3b-5047-4269-9d74-303002a19687"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the fine-tuned YOLOv8 model\n",
        "model = YOLO('/content/drive/MyDrive/AISS - CV/2. Code/Model/runs/detect/train9/weights/best.pt')  # Adjust path as needed\n",
        "\n",
        "# Path to the folder containing new images\n",
        "image_folder = '/content/drive/MyDrive/AISS - CV/3. Daten/Vasilis'  # Adjust path as needed\n",
        "\n",
        "# Path to save the inferred images and annotations\n",
        "output_folder = '/content/drive/MyDrive/AISS - CV/3. Daten/Inferred_Images_Vasilis_2'\n",
        "annotations_folder = '/content/drive/MyDrive/AISS - CV/3. Daten/Inferred_Annotations_Vasilis_2'\n",
        "\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "os.makedirs(annotations_folder, exist_ok=True)\n",
        "\n",
        "# Function to create a YOLO-compatible annotation\n",
        "def create_yolo_annotation(image_path, results, output_annotation_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    h, w, _ = img.shape\n",
        "\n",
        "    annotation_lines = []\n",
        "    for result in results:\n",
        "        for box in result.boxes:\n",
        "            # Ensure there are enough values to unpack\n",
        "            if len(box) >= 6:\n",
        "                x_min, y_min, x_max, y_max, conf, cls = box[:6]\n",
        "\n",
        "                # Calculate normalized coordinates\n",
        "                x_center = (x_min + x_max) / 2.0 / w\n",
        "                y_center = (y_min + y_max) / 2.0 / h\n",
        "                width = (x_max - x_min) / w\n",
        "                height = (y_max - y_min) / h\n",
        "\n",
        "                # Create a line for the annotation file\n",
        "                annotation_line = f\"{int(cls)} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\"\n",
        "                annotation_lines.append(annotation_line)\n",
        "\n",
        "    # Save the annotation to file\n",
        "    with open(output_annotation_path, 'w') as f:\n",
        "        f.write(\"\\n\".join(annotation_lines))\n",
        "\n",
        "    # Print the annotation to console\n",
        "    print(f\"Annotations for {image_path}:\\n\" + \"\\n\".join(annotation_lines))\n",
        "\n",
        "# Perform inference on new images and save results\n",
        "def perform_inference(image_path, output_folder, annotations_folder):\n",
        "    img = cv2.imread(image_path)\n",
        "    results = model(img)\n",
        "\n",
        "    # Debugging: Print the results\n",
        "    print(f\"Performing inference on {image_path}\")\n",
        "\n",
        "    # Save the image with detections\n",
        "    output_image_path = os.path.join(output_folder, os.path.basename(image_path))\n",
        "    annotated_img = results[0].plot(show=False)  # Updated to not display the image\n",
        "    cv2.imwrite(output_image_path, annotated_img)\n",
        "\n",
        "    # Create YOLO-compatible annotation\n",
        "    output_annotation_path = os.path.join(annotations_folder, os.path.splitext(os.path.basename(image_path))[0] + '.txt')\n",
        "    create_yolo_annotation(image_path, results, output_annotation_path)\n",
        "\n",
        "# Iterate over images in the folder and perform inference\n",
        "for img_file in os.listdir(image_folder):\n",
        "    if img_file.endswith(('.jpg', '.jpeg', '.png')):\n",
        "        img_path = os.path.join(image_folder, img_file)\n",
        "        perform_inference(img_path, output_folder, annotations_folder)\n",
        "\n",
        "print(f\"Inference completed. Images and annotations saved to {output_folder} and {annotations_folder}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a38OwdXzF_pb"
      },
      "source": [
        "## Step 4: Definition of Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQaLCE1FGIBF"
      },
      "outputs": [],
      "source": [
        "# Define optimizer and learning rate scheduler\n",
        "# YOLOv8 typically manages these configurations, but we can override them\n",
        "optimizer = torch.optim.SGD(model.model.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zt8OQ-EqGITW"
      },
      "source": [
        "## Step 5: Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fS6Cfd-zGNmf"
      },
      "source": [
        "## Step 6: Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "Y-v4I9BBGQf4",
        "outputId": "dd09d0a9-32b7-432d-c742-abc8e9b063f7"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "model.eval()\n",
        "corrects = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, targets in val_loader:\n",
        "        images = images.to(device)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "        loss, outputs = model.validation_step((images, targets))\n",
        "        corrects += sum([torch.sum(out['labels'] == targ['labels']).item() for out, targ in zip(outputs, targets)])\n",
        "        total += len(targets)\n",
        "\n",
        "print('Validation Accuracy: {:.4f}'.format(corrects / total))\n",
        "\n",
        "# Visualize some predictions\n",
        "model.eval()\n",
        "images, targets = next(iter(val_loader))\n",
        "images = images.to(device)\n",
        "outputs = model(images)\n",
        "for img, target, output in zip(images, targets, outputs):\n",
        "    img = img.cpu().numpy().transpose(1, 2, 0)\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "    print(\"Target:\", target['labels'])\n",
        "    print(\"Output:\", output['labels'])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
